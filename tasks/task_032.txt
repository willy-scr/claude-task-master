# Task ID: 32
# Title: Implement 'learn' Command for Automatic Cursor Rule Generation
# Status: pending
# Dependencies: None
# Priority: high
# Description: Create a new 'learn' command that analyzes code changes and chat history to automatically generate or update Cursor rules in the .cursor/rules directory based on successful implementation patterns.
# Details:
Implement a new command in the task-master CLI that enables Cursor to learn from successful coding patterns:

1. Create a new module `commands/learn.js` that implements the command logic
2. Update `index.js` to register the new command
3. The command should:
   - Accept an optional parameter for specifying which patterns to focus on
   - Use git diff to extract code changes since the last commit
   - Access the Cursor chat history if possible (investigate API or file storage location)
   - Call Claude via ai-services.js with the following context:
     * Code diffs
     * Chat history excerpts showing challenges and solutions
     * Existing rules from .cursor/rules if present
   - Parse Claude's response to extract rule definitions
   - Create or update .mdc files in the .cursor/rules directory
   - Provide a summary of what was learned and which rules were updated

4. Create helper functions to:
   - Extract relevant patterns from diffs
   - Format the prompt for Claude to focus on identifying reusable patterns
   - Parse Claude's response into valid rule definitions
   - Handle rule conflicts or duplications

5. Ensure the command handles errors gracefully, especially if chat history is inaccessible
6. Add appropriate logging to show the learning process
7. Document the command in the README.md file

# Test Strategy:
1. Unit tests:
   - Create tests for each helper function in isolation
   - Mock git diff responses and chat history data
   - Verify rule extraction logic works with different input patterns
   - Test error handling for various failure scenarios

2. Integration tests:
   - Test the command in a repository with actual code changes
   - Verify it correctly generates .mdc files in the .cursor/rules directory
   - Check that generated rules follow the correct format
   - Verify the command correctly updates existing rules without losing custom modifications

3. Manual testing scenarios:
   - Run the command after implementing a feature with specific patterns
   - Verify the generated rules capture the intended patterns
   - Test the command with and without existing rules
   - Verify the command works when chat history is available and when it isn't
   - Test with large diffs to ensure performance remains acceptable

4. Validation:
   - After generating rules, use them in Cursor to verify they correctly guide future implementations
   - Have multiple team members test the command to ensure consistent results
